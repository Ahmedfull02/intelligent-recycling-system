{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7_Ylzvsoo64"
      },
      "source": [
        "**Ultralytics download**\n",
        "to use TOLOv11 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Spliting dataset\n",
        "def split_dataset(dataset_dir, train_ratio=0.8, val_ratio=0.2):\n",
        "    images_dir = os.path.join(dataset_dir, \"images\")\n",
        "    labels_dir = os.path.join(dataset_dir, \"labels\")\n",
        "    \n",
        "    image_files = [f for f in os.listdir(images_dir) if f.endswith(('.jpg'))]\n",
        "    random.shuffle(image_files)\n",
        "    \n",
        "    num_images = len(image_files)\n",
        "    num_train = int(num_images * train_ratio)\n",
        "    \n",
        "    train_images = image_files[:num_train]\n",
        "    val_images = image_files[num_train:]\n",
        "    \n",
        "    # Create train and val directories\n",
        "    for split in ['train', 'val']:\n",
        "        os.makedirs(os.path.join(dataset_dir, split, \"/images\"), exist_ok=True)\n",
        "        os.makedirs(os.path.join(dataset_dir, split, \"/labels\"), exist_ok=True)\n",
        "\n",
        "    def move_files(image_list, dest_images, dest_labels):\n",
        "        for image_file in image_list:\n",
        "            label_file = image_file[:-4] + \".txt\"\n",
        "            \n",
        "            source_image = os.path.join(images_dir, image_file)\n",
        "            source_label = os.path.join(labels_dir, label_file)\n",
        "            \n",
        "            dest_image_path = os.path.join(dest_images, image_file)\n",
        "            dest_label_path = os.path.join(dest_labels, label_file)\n",
        "            \n",
        "            shutil.move(source_image, dest_image_path)\n",
        "            if os.path.exists(source_label):\n",
        "                shutil.move(source_label, dest_label_path)\n",
        "\n",
        "    move_files(train_images, os.path.join(dataset_dir, \"train\", \"images\"), os.path.join(dataset_dir, \"train\", \"labels\"))\n",
        "    move_files(val_images, os.path.join(dataset_dir, \"val\", \"images\"), os.path.join(dataset_dir, \"val\", \"labels\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def augment_image(image_path, output_dir, label_path, num_augments=3):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = Image.fromarray(image)  # Convert to PIL before transforms\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "        transforms.RandomRotation(degrees=30),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    \n",
        "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "    \n",
        "    for i in range(num_augments):\n",
        "        aug_image = transform(image)\n",
        "        aug_image = transforms.ToPILImage()(aug_image)  # Convert tensor back to PIL\n",
        "        aug_filename = f\"{base_name}_aug{i}.jpg\"\n",
        "        aug_image.save(os.path.join(output_dir, aug_filename))  # Save using PIL\n",
        "\n",
        "        if os.path.exists(label_path):\n",
        "            aug_label_filename = f\"{base_name}_aug{i}.txt\"\n",
        "            shutil.copy(label_path, os.path.join(output_dir.replace(\"images\", \"labels\"), aug_label_filename))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset augmentation \n",
        "def augment_dataset(dataset_dir, split=\"train\"):\n",
        "    images_dir = os.path.join(dataset_dir, split, \"images\")\n",
        "    labels_dir = os.path.join(dataset_dir, split, \"labels\")\n",
        "    \n",
        "    image_files = [f for f in os.listdir(images_dir) if f.endswith(('.jpg'))]\n",
        "    \n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(images_dir, image_file)\n",
        "        label_path = os.path.join(labels_dir, image_file[:-4] + \".txt\")\n",
        "        augment_image(image_path, images_dir, label_path, num_augments=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage:\n",
        "dataset_path = \"./dataset\" # Replace with the path to your dataset\n",
        "split_dataset(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data.yaml file created at: ./datasets/data.yaml\n"
          ]
        }
      ],
      "source": [
        "# prompt: custom dataset yaml format for yolo avoid function\n",
        "\n",
        "import os\n",
        "\n",
        "# Define the path to your custom dataset directory\n",
        "dataset_path = \"./datasets/\"  # Replace with the actual path\n",
        "\n",
        "# Create the data.yaml file\n",
        "data_yaml_content = f\"\"\"\n",
        "path: {dataset_path}  # dataset root dir\n",
        "train: train/images  # train images (relative to 'path') 128 images\n",
        "val: val/images  # val images (relative to 'path') 128 images\n",
        "test:  # test images (optional)\n",
        "\n",
        "# Classes\n",
        "names:\n",
        "  0: cardboard\n",
        "  1: glass\n",
        "  2: metal\n",
        "  3: paper\n",
        "  4: plastic\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Create the data.yaml file in the dataset directory\n",
        "with open(os.path.join(dataset_path, \"data.yaml\"), \"w\") as f:\n",
        "  f.write(data_yaml_content)\n",
        "\n",
        "print(f\"data.yaml file created at: {os.path.join(dataset_path, 'data.yaml')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDdLc_8xrHHF",
        "outputId": "74fe734c-bc85-41ae-e022-0a862e503886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLO11n summary: 319 layers, 2,624,080 parameters, 0 gradients, 6.6 GFLOPs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(319, 2624080, 0, 6.614336)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a COCO-pretrained YOLO11n model\n",
        "model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "# Display model information (optional)\n",
        "model.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhZ3yebXMVeG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.75  Python-3.12.9 torch-2.6.0+cpu CPU (Intel Core(TM) i7-6500U 2.50GHz)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=60, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train14, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train14\n",
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    431647  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
            "YOLO11n summary: 319 layers, 2,590,815 parameters, 2,590,799 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\YOGA\\Desktop\\Master s3\\NoSQL\\repo\\intelligent-recycling-system\\datasets\\datasets\\train\\labels... 198 images, 1 backgrounds, 0 corrupt: 100%|██████████| 198/198 [00:02<00:00, 73.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\YOGA\\Desktop\\Master s3\\NoSQL\\repo\\intelligent-recycling-system\\datasets\\datasets\\train\\labels.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\YOGA\\Desktop\\Master s3\\NoSQL\\repo\\intelligent-recycling-system\\datasets\\datasets\\val\\labels... 50 images, 0 backgrounds, 0 corrupt: 100%|██████████| 50/50 [00:00<00:00, 75.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\YOGA\\Desktop\\Master s3\\NoSQL\\repo\\intelligent-recycling-system\\datasets\\datasets\\val\\labels.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs\\detect\\train14\\labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns\\detect\\train14\u001b[0m\n",
            "Starting training for 60 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/60         0G     0.9334       3.39      1.449         16        640: 100%|██████████| 13/13 [03:31<00:00, 16.29s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:14<00:00,  7.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         50         50     0.0872        0.7        0.2      0.134\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/60         0G     0.7588      3.152      1.314         18        640: 100%|██████████| 13/13 [03:59<00:00, 18.39s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<00:00,  8.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         50         50      0.038          1      0.366      0.239\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/60         0G     0.7371      2.862      1.289         13        640: 100%|██████████| 13/13 [04:27<00:00, 20.57s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:14<00:00,  7.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         50         50     0.0125          1      0.358      0.235\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/60         0G     0.8476      2.545      1.363         12        640: 100%|██████████| 13/13 [03:34<00:00, 16.47s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:14<00:00,  7.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         50         50    0.00633       0.96       0.37      0.182\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/60         0G     0.8582      2.165      1.337         18        640: 100%|██████████| 13/13 [03:35<00:00, 16.61s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<00:00,  8.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         50         50      0.854     0.0746       0.28      0.144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/60         0G     0.8341      2.039      1.341         17        640: 100%|██████████| 13/13 [03:25<00:00, 15.83s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:12<00:00,  6.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         50         50      0.328      0.342      0.352      0.221\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/60         0G     0.8463       1.86      1.322         17        640: 100%|██████████| 13/13 [03:05<00:00, 14.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:12<00:00,  6.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         50         50      0.597      0.294      0.497      0.262\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/60         0G     0.8289      1.748      1.329         21        640: 100%|██████████| 13/13 [03:05<00:00, 14.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:12<00:00,  6.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         50         50      0.478      0.623      0.608      0.424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/60         0G     0.8306      1.672      1.337         12        640: 100%|██████████| 13/13 [03:04<00:00, 14.19s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:12<00:00,  6.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         50         50      0.633      0.579      0.611      0.464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/60         0G     0.8018      1.648       1.29         17        640: 100%|██████████| 13/13 [03:05<00:00, 14.28s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:12<00:00,  6.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         50         50       0.66      0.522      0.651       0.48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/60         0G     0.8005      1.587      1.273         15        640: 100%|██████████| 13/13 [03:04<00:00, 14.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:12<00:00,  6.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         50         50      0.595      0.709       0.67      0.504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/60         0G     0.8189      1.578      1.306          9        640: 100%|██████████| 13/13 [03:12<00:00, 14.78s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:13<00:00,  6.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         50         50      0.428       0.62      0.502      0.355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/60         0G     0.7782      1.484      1.259         17        640: 100%|██████████| 13/13 [03:12<00:00, 14.78s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:13<00:00,  6.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         50         50      0.407      0.578      0.464      0.312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/60         0G     0.7877      1.498      1.301         14        640: 100%|██████████| 13/13 [03:12<00:00, 14.84s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:13<00:00,  6.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         50         50      0.376      0.524      0.434      0.303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/60         0G     0.8026      1.435       1.32         15        640: 100%|██████████| 13/13 [03:11<00:00, 14.75s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:12<00:00,  6.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         50         50      0.641      0.452      0.419       0.28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/60         0G     0.8225      1.527      1.305         46        640:  38%|███▊      | 5/13 [25:53<1:10:34, 529.37s/it]"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "results = model.train(data=\"data.yaml\", epochs=60, imgsz=640)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), \"yolo_model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Load the saved weights\n",
        "# model.load_state_dict(torch.load(\"yolo_model.pth\"))\n",
        "# model.eval()  # Set to evaluation mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "872HJTgK0HtD"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "# Initialize the webcam\n",
        "cap = cv2.VideoCapture(0)  # 0 for default webcam\n",
        "\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the webcam\n",
        "    success, frame = cap.read()\n",
        "\n",
        "    if success:\n",
        "        # Run inference on the frame\n",
        "        results = model(frame)\n",
        "\n",
        "        # Get the annotated frame with bounding boxes\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        # Display the annotated frame\n",
        "        cv2.imshow(\"YOLOv8 Object Detection\", annotated_frame)\n",
        "\n",
        "        # Break the loop if 'q' is pressed\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "    else:\n",
        "        print(\"Error reading frame from webcam.\")\n",
        "        break\n",
        "\n",
        "# Release the webcam and close all windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "IRS",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
